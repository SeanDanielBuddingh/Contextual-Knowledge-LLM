The captive, whose heart had leaped within him the instant he saw the Judge, telling him somehow that this was his brother, asked one of the servants who accompanied him what his name was, and whether he knew from what part of the country he came. The servant replied that he was called the Licentiate Juan Perez de Viedma, and that he had heard it said he came from a village in the mountains of Leon. From this statement, and what he himself had seen, he felt convinced that this was his brother who had adopted letters by his father’s advice; and excited and rejoiced, he called Don Fernando and Cardenio and the curate aside, and told them how the matter stood, assuring them that the judge was his brother. The servant had further informed him that he was now going to the Indies with the appointment of Judge of the Supreme Court of Mexico; and he had learned, likewise, that the young lady was his daughter, whose mother had died in giving birth to her, and that he was very rich in consequence of the dowry left to him with the daughter. He asked their advice as to what means he should adopt to make himself known, or to ascertain beforehand whether, when he had made himself known, his brother, seeing him so poor, would be ashamed of him, or would receive him with a warm heart.
The old _principal lodger_, a cross-looking creature, who was thoroughly permeated, so far as her neighbors were concerned, with the inquisitiveness peculiar to envious persons, scrutinized Jean Valjean a great deal, without his suspecting the fact. She was a little deaf, which rendered her talkative. There remained to her from her past, two teeth,—one above, the other below,—which she was continually knocking against each other. She had questioned Cosette, who had not been able to tell her anything, since she knew nothing herself except that she had come from Montfermeil. One morning, this spy saw Jean Valjean, with an air which struck the old gossip as peculiar, entering one of the uninhabited compartments of the hovel. She followed him with the step of an old cat, and was able to observe him without being seen, through a crack in the door, which was directly opposite him. Jean Valjean had his back turned towards this door, by way of greater security, no doubt. The old woman saw him fumble in his pocket and draw thence a case, scissors, and thread; then he began to rip the lining of one of the skirts of his coat, and from the opening he took a bit of yellowish paper, which he unfolded. The old woman recognized, with terror, the fact that it was a bank-bill for a thousand francs. It was the second or third only that she had seen in the course of her existence. She fled in alarm. A moment later, Jean Valjean accosted her, and asked her to go and get this thousand-franc bill changed for him, adding that it was his quarterly income, which he had received the day before. “Where?” thought the old woman. “He did not go out until six o’clock in the evening, and the government bank certainly is not open at that hour.” The old woman went to get the bill changed, and mentioned her surmises. That thousand-franc note, commented on and multiplied, produced a vast amount of terrified discussion among the gossips of the Rue des Vignes Saint-Marcel.
Despite the extreme popularity of deep learning in science and industry, its formal understanding is limited. This thesis puts forth notions of rank as key for developing a theory of deep learning, focusing on the fundamental aspects of generalization and expressiveness. In particular, we establish that gradient-based training can induce an implicit regularization towards low rank for several neural network architectures, and demonstrate empirically that this phenomenon may facilitate an explanation of generalization over natural data (e.g., audio, images, and text). Then, we characterize the ability of graph neural networks to model interactions via a notion of rank, which is commonly used for quantifying entanglement in quantum physics. A central tool underlying these results is a connection between neural networks and tensor factorizations. Practical implications of our theory for designing explicit regularization schemes and data preprocessing algorithms are presented.
Genetic variants (GVs) are defined as differences in the DNA sequences among individuals and play a crucial role in diagnosing and treating genetic diseases. The rapid decrease in next generation sequencing cost has led to an exponential increase in patient-level GV data. This growth poses a challenge for clinicians who must efficiently prioritize patient-specific GVs and integrate them with existing genomic databases to inform patient management. To addressing the interpretation of GVs, genomic foundation models (GFMs) have emerged. However, these models lack standardized performance assessments, leading to considerable variability in model evaluations. This poses the question: How effectively do deep learning methods classify unknown GVs and align them with clinically-verified GVs? We argue that representation learning, which transforms raw data into meaningful feature spaces, is an effective approach for addressing both indexing and classification challenges. We introduce a large-scale Genetic Variant dataset, named GV-Rep, featuring variable-length contexts and detailed annotations, designed for deep learning models to learn GV representations across various traits, diseases, tissue types, and experimental contexts. Our contributions are three-fold: (i) Construction of a comprehensive dataset with 7 million records, each labeled with characteristics of the corresponding variants, alongside additional data from 17,548 gene knockout tests across 1,107 cell types, 1,808 variant combinations, and 156 unique clinically verified GVs from real-world patients. (ii) Analysis of the structure and properties of the dataset. (iii) Experimentation of the dataset with pre-trained GFMs. The results show a significant gap between GFMs current capabilities and accurate GV representation. We hope this dataset will help advance genomic deep learning to bridge this gap.